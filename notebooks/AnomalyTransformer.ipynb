{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AnomalyTransformer\n",
    "- unsupervised learning (no label)\n",
    "- reconstrunction-based approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.DS_Store', 'MSL_test_label.npy', 'MSL_train.npy', 'MSL_test.npy']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.listdir('../data/timeseries/AnomalyTransformer/MSL/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "msl_train = np.load('../data/timeseries/AnomalyTransformer/MSL/MSL_train.npy')\n",
    "msl_test_label = np.load('../data/timeseries/AnomalyTransformer/MSL/MSL_test_label.npy')\n",
    "msl_test = np.load('../data/timeseries/AnomalyTransformer/MSL/MSL_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Anomaly Ratio in test dataset is 10.53 %\n"
     ]
    }
   ],
   "source": [
    "anomaly_ratio = msl_test_label.sum() / len(msl_test_label)\n",
    "print(f'Anomaly Ratio in test dataset is {anomaly_ratio * 100:.2f} %')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(58317, 55)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "msl_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sample data 1 dim\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"sample data 1 dim\")\n",
    "plt.plot(msl_train[:, 0]);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "from copy import deepcopy\n",
    "from datetime import datetime\n",
    "\n",
    "import pandas as pd\n",
    "import torch\n",
    "from pytorch_lightning import Trainer, seed_everything\n",
    "from pytorch_lightning.callbacks import EarlyStopping, ModelCheckpoint, RichProgressBar\n",
    "from pytorch_lightning.callbacks.progress.rich_progress import RichProgressBarTheme\n",
    "from pytorch_lightning.loggers import TensorBoardLogger\n",
    "\n",
    "def define_argparser():\n",
    "    parser = argparse.ArgumentParser()\n",
    "\n",
    "    parser.add_argument(\"--project\", default=\"Time Series Anomaly Detection\")\n",
    "    parser.add_argument(\"--model\", default=\"LitAnomalyTransformer\")\n",
    "    parser.add_argument(\n",
    "        \"--batch_size\",\n",
    "        type=int,\n",
    "        default=512,\n",
    "        help=\"input batch size for training (default: 512)\",\n",
    "    )\n",
    "    parser.add_argument(\n",
    "        \"--epochs\", type=int, default=2, help=\"number of epochs to train (default: 2)\"\n",
    "    )\n",
    "    parser.add_argument(\"--cuda\", type=int, default=0, help=\"0 for cpu -1 for all gpu\")\n",
    "\n",
    "    config = parser.parse_args([])  # jupyter에서는 args=[] 이용\n",
    "\n",
    "    if config.cuda == 0 or not torch.cuda.is_available():\n",
    "        config.cuda = \"cpu\"\n",
    "    else:\n",
    "        config.cuda = \"gpu\"\n",
    "\n",
    "    current_time = str(datetime.today()).split(\".\")[0]\n",
    "    config.current_time = current_time\n",
    "\n",
    "    return config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "config = define_argparser()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Namespace(project='Time Series Anomaly Detection', model='LitAnomalyTransformer', batch_size=512, epochs=2, cuda='cpu', current_time='2023-07-02 14:57:45')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 01.set dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "scaler.fit(msl_train)\n",
    "scaled_train = scaler.transform(msl_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train.shape=(46653, 55)\n",
      "valid.shape=(11664, 55)\n"
     ]
    }
   ],
   "source": [
    "train_ratio = 0.8\n",
    "num_train = int(len(scaled_train)*train_ratio)\n",
    "\n",
    "train = scaled_train[:num_train, :]\n",
    "valid = scaled_train[num_train:, :]\n",
    "\n",
    "print(f'train.shape={train.shape}')\n",
    "print(f'valid.shape={valid.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catchMinor.data_load.dataset import WindowDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = WindowDataset(train, train, window_size=128, overlaps=False, shape='wf')\n",
    "valid_dataset = WindowDataset(valid, valid, window_size=128, overlaps=False, shape='wf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset, batch_size=config.batch_size)\n",
    "valid_loader = DataLoader(valid_dataset, batch_size=config.batch_size)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 02.set model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catchMinor.time_series_model.AnomalyTransformer.at_config import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_config = AnomalyTransformer_config(feature_dim=55)\n",
    "loss_config = AnomalyTransformer_loss_func_config()\n",
    "optim_config = AnomalyTransformer_optimizer_config()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catchMinor.time_series_model.AnomalyTransformer.lit_at import LitAnomalyTransformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-02 14:57:45,720 - INFO - AnomalyTransforme layer is made.\n"
     ]
    }
   ],
   "source": [
    "model = LitAnomalyTransformer(model_config, optim_config, loss_config)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 03. train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (mps), used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n",
      "/Users/kakao/.pyenv/versions/3.10.4/envs/catchMinor/lib/python3.10/site-packages/pytorch_lightning/trainer/setup.py:200: UserWarning: MPS available but not used. Set `accelerator` and `devices` using `Trainer(accelerator='mps', devices=1)`.\n",
      "  rank_zero_warn(\n"
     ]
    }
   ],
   "source": [
    "# callback: tensorboard\n",
    "TensorBoard_logger = TensorBoardLogger(\n",
    "    save_dir=\"./log\", name=config.model, version=config.current_time\n",
    ")\n",
    "\n",
    "# callback: progrss bar\n",
    "rich_progress_bar = RichProgressBar(\n",
    "    theme=RichProgressBarTheme(\n",
    "        description=\"Anomaly Detection\",\n",
    "        progress_bar=\"green1\",\n",
    "        progress_bar_finished=\"green1\",\n",
    "        progress_bar_pulse=\"#6206E0\",\n",
    "        batch_progress=\"green_yellow\",\n",
    "        time=\"grey82\",\n",
    "        processing_speed=\"grey82\",\n",
    "        metrics=\"grey82\",\n",
    "    ),\n",
    "    leave=True,\n",
    ")\n",
    "\n",
    "# callback: save the best model in every epochs\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor=\"train_loss\",\n",
    "    dirpath=\"./checkpoints/\",\n",
    "    filename=\"model_name-{epoch}-{valid_acc:.4f}\",\n",
    "    save_top_k=1,\n",
    "    mode=\"min\",\n",
    ")\n",
    "\n",
    "# callback: early stop\n",
    "early_stopping_callback = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=2)\n",
    "\n",
    "# trainer\n",
    "trainer = Trainer(\n",
    "    log_every_n_steps=1,\n",
    "    accelerator=config.cuda,\n",
    "    logger=TensorBoard_logger,\n",
    "    max_epochs=config.epochs,\n",
    "    deterministic=True,\n",
    "    callbacks=[early_stopping_callback, rich_progress_bar, checkpoint_callback],\n",
    "    check_val_every_n_epoch=1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2.])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.tensor([1.,2.], requires_grad=True)\n",
    "a.detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2.], requires_grad=True)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">   </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Name      </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Type               </span>┃<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\"> Params </span>┃\n",
       "┡━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 0 </span>│ loss_func │ MSELoss            │      0 │\n",
       "│<span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\"> 1 </span>│ model     │ AnomalyTransformer │  9.6 M │\n",
       "└───┴───────────┴────────────────────┴────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━┳━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━┓\n",
       "┃\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mName     \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mType              \u001b[0m\u001b[1;35m \u001b[0m┃\u001b[1;35m \u001b[0m\u001b[1;35mParams\u001b[0m\u001b[1;35m \u001b[0m┃\n",
       "┡━━━╇━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━┩\n",
       "│\u001b[2m \u001b[0m\u001b[2m0\u001b[0m\u001b[2m \u001b[0m│ loss_func │ MSELoss            │      0 │\n",
       "│\u001b[2m \u001b[0m\u001b[2m1\u001b[0m\u001b[2m \u001b[0m│ model     │ AnomalyTransformer │  9.6 M │\n",
       "└───┴───────────┴────────────────────┴────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Trainable params</span>: 9.6 M                                                                                            \n",
       "<span style=\"font-weight: bold\">Non-trainable params</span>: 0                                                                                            \n",
       "<span style=\"font-weight: bold\">Total params</span>: 9.6 M                                                                                                \n",
       "<span style=\"font-weight: bold\">Total estimated model params size (MB)</span>: 38                                                                         \n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mTrainable params\u001b[0m: 9.6 M                                                                                            \n",
       "\u001b[1mNon-trainable params\u001b[0m: 0                                                                                            \n",
       "\u001b[1mTotal params\u001b[0m: 9.6 M                                                                                                \n",
       "\u001b[1mTotal estimated model params size (MB)\u001b[0m: 38                                                                         \n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5eac57d29e2245f5a197582446b06016",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Output()"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/kakao/.pyenv/versions/3.10.4/envs/catchMinor/lib/python3.10/site-packages/pytorch_lightning/trainer/connecto\n",
       "rs/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which \n",
       "may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of \n",
       "cpus on this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/kakao/.pyenv/versions/3.10.4/envs/catchMinor/lib/python3.10/site-packages/pytorch_lightning/trainer/connecto\n",
       "rs/data_connector.py:224: PossibleUserWarning: The dataloader, val_dataloader 0, does not have many workers which \n",
       "may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of \n",
       "cpus on this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">/Users/kakao/.pyenv/versions/3.10.4/envs/catchMinor/lib/python3.10/site-packages/pytorch_lightning/trainer/connecto\n",
       "rs/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which \n",
       "may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of \n",
       "cpus on this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n",
       "</pre>\n"
      ],
      "text/plain": [
       "/Users/kakao/.pyenv/versions/3.10.4/envs/catchMinor/lib/python3.10/site-packages/pytorch_lightning/trainer/connecto\n",
       "rs/data_connector.py:224: PossibleUserWarning: The dataloader, train_dataloader, does not have many workers which \n",
       "may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 10 which is the number of \n",
       "cpus on this machine) in the `DataLoader` init to improve performance.\n",
       "  rank_zero_warn(\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"></pre>\n"
      ],
      "text/plain": []
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "RuntimeError",
     "evalue": "Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[22], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[39m# fit the model\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m trainer\u001b[39m.\u001b[39;49mfit(model, train_loader, valid_loader)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/catchMinor/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:608\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    606\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mTypeError\u001b[39;00m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m`Trainer.fit()` requires a `LightningModule`, got: \u001b[39m\u001b[39m{\u001b[39;00mmodel\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__qualname__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    607\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m_lightning_module \u001b[39m=\u001b[39m model\n\u001b[0;32m--> 608\u001b[0m call\u001b[39m.\u001b[39;49m_call_and_handle_interrupt(\n\u001b[1;32m    609\u001b[0m     \u001b[39mself\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_fit_impl, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path\n\u001b[1;32m    610\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/catchMinor/lib/python3.10/site-packages/pytorch_lightning/trainer/call.py:38\u001b[0m, in \u001b[0;36m_call_and_handle_interrupt\u001b[0;34m(trainer, trainer_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m     36\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mlauncher\u001b[39m.\u001b[39mlaunch(trainer_fn, \u001b[39m*\u001b[39margs, trainer\u001b[39m=\u001b[39mtrainer, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m     37\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 38\u001b[0m         \u001b[39mreturn\u001b[39;00m trainer_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     40\u001b[0m \u001b[39mexcept\u001b[39;00m _TunerExitException:\n\u001b[1;32m     41\u001b[0m     trainer\u001b[39m.\u001b[39m_call_teardown_hook()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/catchMinor/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:650\u001b[0m, in \u001b[0;36mTrainer._fit_impl\u001b[0;34m(self, model, train_dataloaders, val_dataloaders, datamodule, ckpt_path)\u001b[0m\n\u001b[1;32m    643\u001b[0m ckpt_path \u001b[39m=\u001b[39m ckpt_path \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mresume_from_checkpoint\n\u001b[1;32m    644\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_ckpt_path \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39m_set_ckpt_path(\n\u001b[1;32m    645\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mfn,\n\u001b[1;32m    646\u001b[0m     ckpt_path,  \u001b[39m# type: ignore[arg-type]\u001b[39;00m\n\u001b[1;32m    647\u001b[0m     model_provided\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m,\n\u001b[1;32m    648\u001b[0m     model_connected\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m,\n\u001b[1;32m    649\u001b[0m )\n\u001b[0;32m--> 650\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run(model, ckpt_path\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mckpt_path)\n\u001b[1;32m    652\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstate\u001b[39m.\u001b[39mstopped\n\u001b[1;32m    653\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtraining \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/catchMinor/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1103\u001b[0m, in \u001b[0;36mTrainer._run\u001b[0;34m(self, model, ckpt_path)\u001b[0m\n\u001b[1;32m   1099\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mrestore_training_state()\n\u001b[1;32m   1101\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_checkpoint_connector\u001b[39m.\u001b[39mresume_end()\n\u001b[0;32m-> 1103\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_stage()\n\u001b[1;32m   1105\u001b[0m log\u001b[39m.\u001b[39mdetail(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m: trainer tearing down\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m   1106\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_teardown()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/catchMinor/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1182\u001b[0m, in \u001b[0;36mTrainer._run_stage\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1180\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpredicting:\n\u001b[1;32m   1181\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_run_predict()\n\u001b[0;32m-> 1182\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_run_train()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/catchMinor/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1205\u001b[0m, in \u001b[0;36mTrainer._run_train\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1202\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfit_loop\u001b[39m.\u001b[39mtrainer \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\n\u001b[1;32m   1204\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mset_detect_anomaly(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_detect_anomaly):\n\u001b[0;32m-> 1205\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mfit_loop\u001b[39m.\u001b[39;49mrun()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/catchMinor/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/catchMinor/lib/python3.10/site-packages/pytorch_lightning/loops/fit_loop.py:267\u001b[0m, in \u001b[0;36mFitLoop.advance\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    265\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_data_fetcher\u001b[39m.\u001b[39msetup(dataloader, batch_to_device\u001b[39m=\u001b[39mbatch_to_device)\n\u001b[1;32m    266\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_epoch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 267\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mepoch_loop\u001b[39m.\u001b[39;49mrun(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_data_fetcher)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/catchMinor/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/catchMinor/lib/python3.10/site-packages/pytorch_lightning/loops/epoch/training_epoch_loop.py:213\u001b[0m, in \u001b[0;36mTrainingEpochLoop.advance\u001b[0;34m(self, data_fetcher)\u001b[0m\n\u001b[1;32m    210\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_started()\n\u001b[1;32m    212\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39m\"\u001b[39m\u001b[39mrun_training_batch\u001b[39m\u001b[39m\"\u001b[39m):\n\u001b[0;32m--> 213\u001b[0m         batch_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbatch_loop\u001b[39m.\u001b[39;49mrun(kwargs)\n\u001b[1;32m    215\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mbatch_progress\u001b[39m.\u001b[39mincrement_processed()\n\u001b[1;32m    217\u001b[0m \u001b[39m# update non-plateau LR schedulers\u001b[39;00m\n\u001b[1;32m    218\u001b[0m \u001b[39m# update epoch-interval ones only when we are at the end of training epoch\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/catchMinor/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/catchMinor/lib/python3.10/site-packages/pytorch_lightning/loops/batch/training_batch_loop.py:90\u001b[0m, in \u001b[0;36mTrainingBatchLoop.advance\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m     88\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moptimizer_loop\u001b[39m.\u001b[39mrun(optimizers, kwargs)\n\u001b[1;32m     89\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m---> 90\u001b[0m     outputs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmanual_loop\u001b[39m.\u001b[39;49mrun(kwargs)\n\u001b[1;32m     91\u001b[0m \u001b[39mif\u001b[39;00m outputs:\n\u001b[1;32m     92\u001b[0m     \u001b[39m# automatic: can be empty if all optimizers skip their batches\u001b[39;00m\n\u001b[1;32m     93\u001b[0m     \u001b[39m# manual: #9052 added support for raising `StopIteration` in the `training_step`. If that happens,\u001b[39;00m\n\u001b[1;32m     94\u001b[0m     \u001b[39m# then `advance` doesn't finish and an empty dict is returned\u001b[39;00m\n\u001b[1;32m     95\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_outputs\u001b[39m.\u001b[39mappend(outputs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/catchMinor/lib/python3.10/site-packages/pytorch_lightning/loops/loop.py:199\u001b[0m, in \u001b[0;36mLoop.run\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    197\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m    198\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_start(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m--> 199\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49madvance(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    200\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_advance_end()\n\u001b[1;32m    201\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_restarting \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/catchMinor/lib/python3.10/site-packages/pytorch_lightning/loops/optimization/manual_loop.py:110\u001b[0m, in \u001b[0;36mManualOptimization.advance\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    107\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_kwargs(kwargs, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_hiddens)\n\u001b[1;32m    109\u001b[0m \u001b[39m# manually capture logged metrics\u001b[39;00m\n\u001b[0;32m--> 110\u001b[0m training_step_output \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49m_call_strategy_hook(\u001b[39m\"\u001b[39;49m\u001b[39mtraining_step\u001b[39;49m\u001b[39m\"\u001b[39;49m, \u001b[39m*\u001b[39;49mkwargs\u001b[39m.\u001b[39;49mvalues())\n\u001b[1;32m    111\u001b[0m \u001b[39mdel\u001b[39;00m kwargs  \u001b[39m# release the batch from memory\u001b[39;00m\n\u001b[1;32m    112\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtrainer\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39mpost_training_step()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/catchMinor/lib/python3.10/site-packages/pytorch_lightning/trainer/trainer.py:1485\u001b[0m, in \u001b[0;36mTrainer._call_strategy_hook\u001b[0;34m(self, hook_name, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1482\u001b[0m     \u001b[39mreturn\u001b[39;00m\n\u001b[1;32m   1484\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mprofile(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m[Strategy]\u001b[39m\u001b[39m{\u001b[39;00m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mstrategy\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m.\u001b[39m\u001b[39m{\u001b[39;00mhook_name\u001b[39m}\u001b[39;00m\u001b[39m\"\u001b[39m):\n\u001b[0;32m-> 1485\u001b[0m     output \u001b[39m=\u001b[39m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1487\u001b[0m \u001b[39m# restore current_fx when nested context\u001b[39;00m\n\u001b[1;32m   1488\u001b[0m pl_module\u001b[39m.\u001b[39m_current_fx_name \u001b[39m=\u001b[39m prev_fx_name\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/catchMinor/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:378\u001b[0m, in \u001b[0;36mStrategy.training_step\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    376\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mtrain_step_context():\n\u001b[1;32m    377\u001b[0m     \u001b[39massert\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmodel, TrainingStep)\n\u001b[0;32m--> 378\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmodel\u001b[39m.\u001b[39;49mtraining_step(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/study/catchMinor/catchMinor/time_series_model/AnomalyTransformer/lit_at.py:66\u001b[0m, in \u001b[0;36mLitAnomalyTransformer.training_step\u001b[0;34m(self, batch, batch_idx)\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[39m# minimize phase\u001b[39;00m\n\u001b[1;32m     65\u001b[0m loss2 \u001b[39m=\u001b[39m recon_loss \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mLambda \u001b[39m*\u001b[39m prior_loss\n\u001b[0;32m---> 66\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mmanual_backward(loss2)\n\u001b[1;32m     67\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     68\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/catchMinor/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1466\u001b[0m, in \u001b[0;36mLightningModule.manual_backward\u001b[0;34m(self, loss, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1464\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1465\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_verify_is_manual_optimization(\u001b[39m\"\u001b[39m\u001b[39mmanual_backward\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m-> 1466\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrainer\u001b[39m.\u001b[39;49mstrategy\u001b[39m.\u001b[39;49mbackward(loss, \u001b[39mNone\u001b[39;49;00m, \u001b[39mNone\u001b[39;49;00m, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/catchMinor/lib/python3.10/site-packages/pytorch_lightning/strategies/strategy.py:207\u001b[0m, in \u001b[0;36mStrategy.backward\u001b[0;34m(self, closure_loss, optimizer, optimizer_idx, *args, **kwargs)\u001b[0m\n\u001b[1;32m    204\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    205\u001b[0m closure_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mpre_backward(closure_loss, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module)\n\u001b[0;32m--> 207\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mprecision_plugin\u001b[39m.\u001b[39;49mbackward(closure_loss, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mlightning_module, optimizer, optimizer_idx, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    209\u001b[0m closure_loss \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mprecision_plugin\u001b[39m.\u001b[39mpost_backward(closure_loss, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlightning_module)\n\u001b[1;32m    210\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mpost_backward(closure_loss)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/catchMinor/lib/python3.10/site-packages/pytorch_lightning/plugins/precision/precision_plugin.py:67\u001b[0m, in \u001b[0;36mPrecisionPlugin.backward\u001b[0;34m(self, tensor, model, optimizer, optimizer_idx, *args, **kwargs)\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mbackward\u001b[39m(  \u001b[39m# type: ignore[override]\u001b[39;00m\n\u001b[1;32m     48\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m     49\u001b[0m     tensor: Tensor,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs: Any,\n\u001b[1;32m     55\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     56\u001b[0m \u001b[39m    \u001b[39m\u001b[39mr\u001b[39m\u001b[39m\"\"\"Performs the actual backpropagation.\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \n\u001b[1;32m     58\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39m        \\**kwargs: Keyword arguments for the same purpose as ``*args``.\u001b[39;00m\n\u001b[1;32m     66\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 67\u001b[0m     model\u001b[39m.\u001b[39;49mbackward(tensor, optimizer, optimizer_idx, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/catchMinor/lib/python3.10/site-packages/pytorch_lightning/core/module.py:1488\u001b[0m, in \u001b[0;36mLightningModule.backward\u001b[0;34m(self, loss, optimizer, optimizer_idx, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1486\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_fabric\u001b[39m.\u001b[39mbackward(loss, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[1;32m   1487\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 1488\u001b[0m     loss\u001b[39m.\u001b[39;49mbackward(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/catchMinor/lib/python3.10/site-packages/torch/_tensor.py:488\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    478\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    479\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    480\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    481\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    486\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    487\u001b[0m     )\n\u001b[0;32m--> 488\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    489\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    490\u001b[0m )\n",
      "File \u001b[0;32m~/.pyenv/versions/3.10.4/envs/catchMinor/lib/python3.10/site-packages/torch/autograd/__init__.py:197\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    192\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    194\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    195\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    196\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 197\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    198\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    199\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
     ]
    }
   ],
   "source": [
    "# fit the model\n",
    "trainer.fit(model, train_loader, valid_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load best model (min train_loss)\n",
    "checkpoint = torch.load(checkpoint_callback.best_model_path)\n",
    "model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "\n",
    "preds = []\n",
    "with torch.no_grad():\n",
    "    model.eval()\n",
    "    # predict\n",
    "    for batch in valid_loader:\n",
    "        x, y = batch\n",
    "        pred = model(x).detach().numpy().tolist()\n",
    "        preds += pred\n",
    "\n",
    "    # anomaly score\n",
    "    anomaly_scores = []\n",
    "    for batch in valid_loader:\n",
    "        anomaly_score = model.get_anomaly_score(batch).detach().numpy().tolist()\n",
    "        anomaly_scores += anomaly_score\n",
    "\n",
    "result = pd.DataFrame({\"label\": mix_y_test, \"anomaly_score\": anomaly_scores})\n",
    "print(result.groupby(\"label\")[\"anomaly_score\"].mean())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "catchMinor",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
